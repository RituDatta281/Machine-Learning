{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 306,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import math\n",
    "import random\n",
    "from copy import copy, deepcopy\n",
    "import string\n",
    "import nltk\n",
    "from nltk.tokenize import word_tokenize\n",
    "from nltk.corpus import stopwords\n",
    "from nltk.stem import WordNetLemmatizer\n",
    "from nltk.stem import PorterStemmer\n",
    "import re\n",
    "from bs4 import BeautifulSoup as bs\n",
    "from numpy.linalg import norm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 307,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['Coffee', 'Arduino', 'Anime', 'Astronomy', 'Biology', 'Chess', 'Cooking', 'Law', 'Space', 'Windows_Phone', 'Word_Working']\n"
     ]
    }
   ],
   "source": [
    "inputs = []\n",
    "with open('Data/topics.txt','r',encoding='utf-8') as file:\n",
    "    for line in file:\n",
    "        line = line[:-1]\n",
    "        inputs.append(line)\n",
    "    print(inputs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "metadata": {},
   "outputs": [],
   "source": [
    "def Text_Preprocessing(input_type):\n",
    "    input_file = \"Data/Training/\"+ input_type + \".xml\"\n",
    "    array = []\n",
    "    with open(input_file,'r',encoding='utf-8') as file:\n",
    "        content = file.read()\n",
    "        soup = bs(content)\n",
    "        for items in soup.findAll(\"row\"):\n",
    "            Document = dict()\n",
    "            body = items['body']\n",
    "\n",
    "            # removing tags and numbers using regex        \n",
    "#             body = re.sub(r'<[^>]*>','', body)\n",
    "            body = re.sub(r'[-+]?\\d+', '', body)\n",
    "            body = re.sub(r'[^\\x00-\\x7F]', ' ', body)\n",
    "\n",
    "            #Lowercase the text\n",
    "            body = body.lower()\n",
    "\n",
    "            #Remove punctuations\n",
    "            body = body.translate((str.maketrans('','',string.punctuation)))\n",
    "\n",
    "            #Tokenize\n",
    "            body = word_tokenize(body)\n",
    "\n",
    "            #Remove stopwords\n",
    "            stop_words = set(stopwords.words('english'))\n",
    "            body = [word for word in body if not word in stop_words]\n",
    "\n",
    "            #Lemmatize tokens\n",
    "            lemmatizer = WordNetLemmatizer()\n",
    "            body = [lemmatizer.lemmatize(word) for word in body]\n",
    "\n",
    "            #Stemming tokens\n",
    "            stemmer= PorterStemmer()\n",
    "            body = [stemmer.stem(word) for word in body]\n",
    "            \n",
    "            if not body:\n",
    "                continue\n",
    "            \n",
    "            Document[input_type] = body\n",
    "            \n",
    "            array.append(Document)\n",
    "            #print(body, \"\\n\\n\\n\")\n",
    "        #print(array)\n",
    "        return array"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "metadata": {},
   "outputs": [],
   "source": [
    "Training_set = []\n",
    "Validation_set = []\n",
    "Test_set = []\n",
    "for input_file in inputs:\n",
    "    array = Text_Preprocessing(input_file)\n",
    "    Training_set += array[:500]\n",
    "    Validation_set += array[500:500+200]\n",
    "    Test_set += array[700:1200]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1500\n",
      "600\n",
      "1500\n"
     ]
    }
   ],
   "source": [
    "print(len(Training_set))\n",
    "print(len(Validation_set))\n",
    "print(len(Test_set))\n",
    "# print(Training_set)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "17306\n"
     ]
    }
   ],
   "source": [
    "FeatureSpace = []\n",
    "for document in Training_set:\n",
    "    temp = list(document.values())\n",
    "    for i in temp[0]:\n",
    "        if i not in FeatureSpace:\n",
    "            FeatureSpace.append(i)\n",
    "print(len(FeatureSpace))\n",
    "# print(FeatureSpace)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "metadata": {},
   "outputs": [],
   "source": [
    "Y_train = []\n",
    "X_train_HD = []\n",
    "X_train_ED = []\n",
    "\n",
    "X_Validation_HD = []\n",
    "X_Validation_ED = []\n",
    "Y_Validation =[]\n",
    "\n",
    "X_test_HD = []\n",
    "X_test_ED = []\n",
    "Y_test = []\n",
    "\n",
    "for i in range(len(Training_set)):\n",
    "    Y_train.append(list(Training_set[i].keys())[0])\n",
    "    temp = list(Training_set[i].values())[0]\n",
    "    HD = []\n",
    "    ED = []\n",
    "    for i in range(len(FeatureSpace)):\n",
    "        if FeatureSpace[i] in temp:\n",
    "            HD.append(1)\n",
    "        else:\n",
    "            HD.append(0)\n",
    "        \n",
    "        ED.append(temp.count(FeatureSpace[i]))\n",
    "        \n",
    "    X_train_HD.append(HD)\n",
    "    X_train_ED.append(ED)\n",
    "\n",
    "for i in range(len(Test_set)):\n",
    "    Y_test.append(list(Test_set[i].keys())[0])\n",
    "    temp = list(Test_set[i].values())[0]\n",
    "    HD = []\n",
    "    ED = []\n",
    "    for i in range(len(FeatureSpace)):\n",
    "        if FeatureSpace[i] in temp:\n",
    "            HD.append(1)\n",
    "        else:\n",
    "            HD.append(0)\n",
    "        \n",
    "        ED.append(temp.count(FeatureSpace[i]))\n",
    "        \n",
    "    X_test_HD.append(HD)\n",
    "    X_test_ED.append(ED)\n",
    "    \n",
    "    \n",
    "for i in range(len(Validation_set)):\n",
    "    Y_Validation.append(list(Validation_set[i].keys())[0])\n",
    "    temp = list(Validation_set[i].values())[0]\n",
    "    HD = []\n",
    "    ED = []\n",
    "    for i in range(len(FeatureSpace)):\n",
    "        if FeatureSpace[i] in temp:\n",
    "            HD.append(1)\n",
    "        else:\n",
    "            HD.append(0)\n",
    "        \n",
    "        ED.append(temp.count(FeatureSpace[i]))\n",
    "        \n",
    "    X_Validation_HD.append(HD)\n",
    "    X_Validation_ED.append(ED)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "17306\n"
     ]
    }
   ],
   "source": [
    "print(len(X_Validation_HD[0]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "def getDistance(Dt,D1):\n",
    "    count = 0\n",
    "    for i in range(len(D1)):\n",
    "        if D1[i] != Dt[i]:\n",
    "            count += 1\n",
    "    return count"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [],
   "source": [
    "def HammingDistance(Dt, X_train, Y_train, k = 3):\n",
    "    Hamming_D = []\n",
    "    for i in range(len(X_train)):\n",
    "        Hamming_D.append(getDistance(Dt, X_train[i]))\n",
    "        \n",
    "#     print(Hamming_D)\n",
    "    \n",
    "    indices = sorted(range(len(Hamming_D)), key = lambda sub: Hamming_D[sub])[:k] \n",
    "    Y_output = []\n",
    "    for i in indices:\n",
    "        Y_output.append(Y_train[i])   \n",
    "    output = max(set(Y_output), key = Y_output.count) \n",
    "    return output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 262,
   "metadata": {},
   "outputs": [],
   "source": [
    "def HammingDistance_Accuracy(X_Validation_HD, Y_Validation, X_train_HD, Y_train):\n",
    "    count = 0\n",
    "    for i in range(len(X_Validation_HD)):\n",
    "        if Y_Validation[i] == HammingDistance(X_Validation_HD[i], X_train_HD, Y_train):\n",
    "            count += 1\n",
    "            print(count)\n",
    "    print(\"Accuracy is: \", (count/len(Y_Validation) * 100))\n",
    "\n",
    "# print(HammingDistance(X_test_HD[1300], X_train_HD, Y_train))\n",
    "# print(Y_test[1300])\n",
    "# HammingDistance_Accuracy(X_Validation_HD, Y_Validation, X_train_HD, Y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 265,
   "metadata": {},
   "outputs": [],
   "source": [
    "def CalculateED(Dt,D):\n",
    "    value = 0\n",
    "    for i in range(len(D)):\n",
    "        value += pow(Dt[i] - D[i], 2)\n",
    "    value = math.sqrt(value)\n",
    "    return value"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 266,
   "metadata": {},
   "outputs": [],
   "source": [
    "def EuclideanDistance(Dt, X_train, Y_train, k):\n",
    "    Euclidean_D = []\n",
    "    for i in range(len(X_train)):\n",
    "        Euclidean_D.append(CalculateED(Dt, X_train[i]))\n",
    "    \n",
    "    #find k minimum indices\n",
    "    indices = sorted(range(len(Euclidean_D)), key = lambda sub: Euclidean_D[sub])[:k] \n",
    "    Y_output = []\n",
    "    for i in indices:\n",
    "        Y_output.append(Y_train[i])   \n",
    "    \n",
    "    #find higher frequency result\n",
    "    output = max(set(Y_output), key = Y_output.count) \n",
    "    return output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def EuclideanDistance_Accuracy(X_Validation_ED, Y_Validation, X_train_ED, Y_train, k):\n",
    "    count = 0\n",
    "    for i in range(len(X_Validation_ED)):\n",
    "        if Y_Validation[i] == EuclideanDistance(X_Validation_ED[i], X_train_ED, Y_train, k):\n",
    "            count += 1\n",
    "            print(count)\n",
    "    print(\"Accuracy is: \", (count/len(Y_Validation) * 100))\n",
    "\n",
    "# HammingDistance(X_Validation_HD[0], X_train_HD, Y_train)\n",
    "# print(Y_Validation[0])\n",
    "# EuclideanDistance_Accuracy(X_Validation_ED, Y_Validation, X_train_ED, Y_train, 5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(EuclideanDistance(X_test_ED[1400], X_train_ED.copy(), Y_train.copy(),5))\n",
    "print(Y_test[1400])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 275,
   "metadata": {},
   "outputs": [],
   "source": [
    "number_of_documents = len(X_train_HD)\n",
    "d_word = np.sum(X_train_HD.copy(), axis=0)\n",
    "# print(sum(d_word))\n",
    "# print(len(d_word))\n",
    "# print(number_of_documents)\n",
    "IDF = []\n",
    "for i in range(len(d_word)):\n",
    "    temp = math.log2(number_of_documents/d_word[i])\n",
    "    if temp <= 0:\n",
    "        IDF.append(0.0001)\n",
    "    else:\n",
    "        IDF.append(temp)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 276,
   "metadata": {},
   "outputs": [],
   "source": [
    "def setWeight(D, Dt):\n",
    "    totalWords_D = sum(D)\n",
    "    totalWords_Dt = sum(Dt)\n",
    "    for i in range(len(D)):\n",
    "#         TF_D = D[i]/totalWords_D\n",
    "#         TF_Dt = Dt[i]/totalWords_Dt\n",
    "        if D[i] != 0:\n",
    "            D[i] = (D[i]/totalWords_D) * IDF[i]\n",
    "        if Dt[i] != 0 :\n",
    "            Dt[i] = (Dt[i]/totalWords_Dt) * IDF[i]\n",
    "    return D,Dt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 285,
   "metadata": {},
   "outputs": [],
   "source": [
    "def CosineTheta(D , Dt):\n",
    "    return np.dot(D,Dt)/(norm(D)*norm(Dt))\n",
    "#     D, Dt = setWeight (D,Dt)\n",
    "#     dotProduct = np.dot(D,Dt)\n",
    "#     length_D = math.sqrt(np.dot(D, D))\n",
    "#     length_Dt = math.sqrt(np.dot(Dt, Dt))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 300,
   "metadata": {},
   "outputs": [],
   "source": [
    "def CosineSimilarity(Dt, X_train, Y_train, k):\n",
    "    Cosine_values = []\n",
    "    output = []\n",
    "    for D in X_train:\n",
    "        Cosine_values.append(CosineTheta(D,Dt))\n",
    "\n",
    "    for k in K:\n",
    "        indices = (sorted(range(len(Cosine_values)), key = lambda sub: Cosine_values[sub])[-k:])\n",
    "        Y_output = []\n",
    "        for i in indices:\n",
    "            Y_output.append(Y_train[i])\n",
    "\n",
    "        output.append(max(set(Y_output), key = Y_output.count))\n",
    "    \n",
    "    return output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 301,
   "metadata": {},
   "outputs": [],
   "source": [
    "# print(CosineSimilarity(X_test_ED[1400].copy(), deepcopy(X_train_ED), deepcopy(Y_train), 5))\n",
    "# print(Y_test[1400])\n",
    "K= [1,3,5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 305,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 [1, 1, 1]\n",
      "1 [2, 2, 1]\n",
      "2 [3, 3, 2]\n",
      "3 [4, 4, 3]\n",
      "4 [5, 5, 4]\n",
      "5 [6, 6, 5]\n",
      "6 [7, 7, 6]\n",
      "7 [8, 8, 7]\n",
      "8 [9, 9, 8]\n",
      "9 [10, 10, 9]\n",
      "10 [11, 11, 10]\n",
      "11 [11, 11, 10]\n",
      "12 [12, 12, 11]\n",
      "13 [13, 13, 12]\n",
      "14 [14, 14, 13]\n",
      "15 [15, 15, 14]\n",
      "16 [16, 16, 15]\n",
      "17 [17, 17, 16]\n",
      "18 [18, 18, 17]\n",
      "19 [19, 19, 18]\n",
      "20 [20, 20, 19]\n",
      "21 [21, 21, 20]\n",
      "22 [22, 22, 21]\n",
      "23 [23, 23, 22]\n",
      "24 [24, 24, 23]\n",
      "25 [25, 25, 24]\n",
      "26 [26, 26, 25]\n",
      "27 [27, 27, 26]\n",
      "28 [28, 28, 27]\n",
      "29 [29, 29, 28]\n",
      "30 [30, 30, 29]\n",
      "31 [31, 31, 30]\n",
      "32 [32, 32, 31]\n",
      "33 [33, 33, 32]\n",
      "34 [34, 34, 33]\n",
      "35 [35, 35, 34]\n",
      "36 [36, 36, 35]\n",
      "37 [37, 36, 35]\n",
      "38 [38, 37, 36]\n",
      "39 [39, 38, 37]\n",
      "40 [40, 39, 38]\n",
      "41 [41, 40, 39]\n",
      "42 [42, 41, 40]\n",
      "43 [43, 42, 41]\n",
      "44 [44, 43, 42]\n",
      "45 [45, 44, 43]\n",
      "46 [46, 45, 44]\n",
      "47 [47, 46, 45]\n",
      "48 [48, 47, 46]\n",
      "49 [49, 48, 47]\n",
      "50 [50, 49, 48]\n",
      "51 [51, 50, 49]\n",
      "52 [52, 51, 50]\n",
      "53 [53, 52, 51]\n",
      "54 [54, 53, 52]\n",
      "55 [55, 54, 53]\n",
      "56 [56, 55, 54]\n",
      "57 [57, 56, 55]\n",
      "58 [58, 57, 56]\n",
      "59 [59, 58, 57]\n",
      "60 [60, 59, 58]\n",
      "61 [61, 60, 59]\n",
      "62 [62, 61, 60]\n",
      "63 [63, 62, 61]\n",
      "64 [64, 63, 62]\n",
      "65 [65, 64, 63]\n",
      "66 [66, 65, 64]\n",
      "67 [67, 66, 65]\n",
      "68 [68, 67, 66]\n",
      "69 [69, 68, 67]\n",
      "70 [70, 69, 68]\n",
      "71 [71, 70, 69]\n",
      "72 [72, 71, 70]\n",
      "73 [73, 72, 71]\n",
      "74 [74, 73, 72]\n",
      "75 [75, 74, 73]\n",
      "76 [76, 75, 74]\n",
      "77 [77, 76, 75]\n",
      "78 [78, 77, 76]\n",
      "79 [79, 78, 77]\n",
      "80 [80, 79, 78]\n",
      "81 [81, 80, 79]\n",
      "82 [82, 81, 80]\n",
      "83 [82, 81, 81]\n",
      "84 [83, 82, 82]\n",
      "85 [84, 83, 83]\n",
      "86 [85, 83, 84]\n",
      "87 [86, 84, 85]\n",
      "88 [86, 84, 85]\n",
      "89 [87, 85, 86]\n",
      "90 [88, 86, 87]\n",
      "91 [89, 87, 88]\n",
      "92 [90, 88, 89]\n",
      "93 [91, 89, 90]\n",
      "94 [92, 90, 91]\n",
      "95 [93, 91, 92]\n",
      "96 [94, 92, 93]\n",
      "97 [95, 93, 94]\n",
      "98 [96, 94, 95]\n",
      "99 [97, 95, 96]\n",
      "100 [98, 96, 97]\n",
      "101 [99, 97, 98]\n",
      "102 [100, 98, 99]\n",
      "103 [101, 99, 100]\n",
      "104 [102, 100, 101]\n",
      "105 [102, 101, 101]\n",
      "106 [103, 102, 102]\n",
      "107 [104, 103, 103]\n",
      "108 [105, 104, 104]\n",
      "109 [106, 105, 105]\n",
      "110 [107, 106, 106]\n",
      "111 [108, 107, 107]\n",
      "112 [109, 108, 108]\n",
      "113 [110, 109, 109]\n",
      "114 [111, 110, 110]\n",
      "115 [112, 111, 111]\n",
      "116 [112, 111, 111]\n",
      "117 [113, 112, 112]\n",
      "118 [114, 113, 113]\n",
      "119 [115, 114, 114]\n",
      "120 [116, 115, 115]\n",
      "121 [117, 116, 116]\n",
      "122 [118, 117, 117]\n",
      "123 [119, 118, 118]\n",
      "124 [120, 119, 119]\n",
      "125 [121, 120, 120]\n",
      "126 [122, 121, 121]\n",
      "127 [123, 122, 122]\n",
      "128 [124, 123, 123]\n",
      "129 [125, 124, 124]\n",
      "130 [126, 125, 125]\n",
      "131 [127, 126, 126]\n",
      "132 [128, 127, 127]\n",
      "133 [129, 128, 128]\n",
      "134 [130, 129, 129]\n",
      "135 [130, 129, 129]\n",
      "136 [131, 130, 130]\n",
      "137 [132, 131, 131]\n",
      "138 [132, 131, 131]\n",
      "139 [133, 132, 132]\n",
      "140 [134, 133, 133]\n",
      "141 [135, 134, 134]\n",
      "142 [135, 134, 134]\n",
      "143 [136, 135, 135]\n",
      "144 [137, 136, 136]\n",
      "145 [138, 137, 137]\n",
      "146 [139, 138, 138]\n",
      "147 [140, 139, 139]\n",
      "148 [140, 140, 139]\n",
      "149 [140, 140, 139]\n",
      "150 [141, 141, 140]\n",
      "151 [142, 142, 141]\n",
      "152 [143, 143, 142]\n",
      "153 [144, 144, 143]\n",
      "154 [145, 145, 144]\n",
      "155 [146, 146, 145]\n",
      "156 [147, 147, 146]\n",
      "157 [148, 148, 147]\n",
      "158 [148, 148, 147]\n",
      "159 [149, 149, 148]\n",
      "160 [150, 150, 149]\n",
      "161 [151, 151, 150]\n",
      "162 [152, 152, 151]\n",
      "163 [153, 153, 152]\n",
      "164 [154, 154, 153]\n",
      "165 [155, 155, 154]\n",
      "166 [156, 156, 155]\n",
      "167 [157, 157, 156]\n",
      "168 [158, 158, 157]\n",
      "169 [159, 159, 158]\n",
      "170 [160, 160, 159]\n",
      "171 [161, 161, 160]\n",
      "172 [162, 162, 161]\n",
      "173 [163, 163, 162]\n",
      "174 [164, 164, 163]\n",
      "175 [165, 165, 164]\n",
      "176 [166, 166, 165]\n",
      "177 [167, 167, 166]\n",
      "178 [168, 168, 167]\n",
      "179 [169, 169, 168]\n",
      "180 [170, 170, 169]\n",
      "181 [171, 171, 170]\n",
      "182 [172, 172, 171]\n",
      "183 [173, 173, 172]\n",
      "184 [174, 174, 173]\n",
      "185 [175, 175, 174]\n",
      "186 [176, 176, 175]\n",
      "187 [177, 177, 176]\n",
      "188 [178, 178, 177]\n",
      "189 [178, 179, 178]\n",
      "190 [179, 180, 179]\n",
      "191 [180, 181, 180]\n",
      "192 [181, 182, 181]\n",
      "193 [182, 183, 182]\n",
      "194 [183, 184, 183]\n",
      "195 [184, 185, 184]\n",
      "196 [185, 186, 185]\n",
      "197 [186, 187, 186]\n",
      "198 [187, 188, 187]\n",
      "199 [187, 188, 187]\n",
      "200 [188, 189, 188]\n",
      "201 [189, 190, 189]\n",
      "202 [190, 191, 190]\n",
      "203 [191, 192, 191]\n",
      "204 [192, 193, 192]\n",
      "205 [193, 194, 193]\n",
      "206 [194, 195, 194]\n",
      "207 [195, 196, 195]\n",
      "208 [196, 197, 196]\n",
      "209 [196, 197, 196]\n",
      "210 [197, 198, 197]\n",
      "211 [198, 199, 198]\n",
      "212 [199, 200, 199]\n",
      "213 [200, 201, 200]\n",
      "214 [201, 202, 201]\n",
      "215 [202, 203, 202]\n",
      "216 [203, 204, 203]\n",
      "217 [204, 205, 204]\n",
      "218 [205, 205, 204]\n",
      "219 [206, 206, 205]\n",
      "220 [207, 207, 206]\n",
      "221 [208, 208, 207]\n",
      "222 [209, 208, 207]\n",
      "223 [210, 209, 208]\n",
      "224 [211, 210, 209]\n",
      "225 [212, 211, 210]\n",
      "226 [212, 211, 211]\n",
      "227 [213, 212, 212]\n",
      "228 [214, 213, 213]\n",
      "229 [215, 214, 214]\n",
      "230 [216, 215, 215]\n",
      "231 [217, 216, 216]\n",
      "232 [218, 217, 217]\n",
      "233 [219, 218, 218]\n",
      "234 [220, 219, 219]\n",
      "235 [221, 220, 220]\n",
      "236 [222, 221, 221]\n",
      "237 [223, 222, 222]\n",
      "238 [224, 223, 223]\n",
      "239 [225, 224, 224]\n",
      "240 [226, 225, 225]\n",
      "241 [227, 226, 226]\n",
      "242 [228, 227, 227]\n",
      "243 [229, 228, 228]\n",
      "244 [229, 229, 229]\n",
      "245 [230, 230, 230]\n",
      "246 [231, 231, 231]\n",
      "247 [232, 232, 232]\n",
      "248 [233, 233, 233]\n",
      "249 [234, 234, 234]\n",
      "250 [235, 235, 235]\n",
      "251 [236, 236, 236]\n",
      "252 [237, 237, 237]\n",
      "253 [238, 238, 238]\n",
      "254 [239, 239, 239]\n",
      "255 [240, 239, 239]\n",
      "256 [240, 240, 240]\n",
      "257 [241, 241, 241]\n",
      "258 [242, 242, 242]\n",
      "259 [243, 243, 243]\n",
      "260 [244, 244, 244]\n",
      "261 [245, 245, 245]\n",
      "262 [246, 246, 246]\n",
      "263 [247, 247, 247]\n",
      "264 [248, 248, 248]\n",
      "265 [249, 249, 249]\n",
      "266 [250, 250, 250]\n",
      "267 [251, 251, 251]\n",
      "268 [252, 252, 252]\n",
      "269 [253, 253, 253]\n",
      "270 [254, 254, 254]\n",
      "271 [255, 255, 255]\n",
      "272 [256, 256, 256]\n",
      "273 [257, 257, 257]\n",
      "274 [258, 258, 258]\n",
      "275 [259, 259, 259]\n",
      "276 [260, 259, 259]\n",
      "277 [261, 260, 260]\n",
      "278 [262, 261, 261]\n",
      "279 [263, 262, 262]\n",
      "280 [264, 263, 263]\n",
      "281 [265, 264, 264]\n",
      "282 [266, 265, 265]\n",
      "283 [267, 266, 266]\n",
      "284 [268, 267, 267]\n",
      "285 [269, 268, 268]\n",
      "286 [270, 269, 269]\n",
      "287 [271, 270, 270]\n",
      "288 [272, 271, 271]\n",
      "289 [273, 272, 272]\n",
      "290 [274, 273, 273]\n",
      "291 [275, 274, 274]\n",
      "292 [276, 275, 275]\n",
      "293 [277, 276, 276]\n",
      "294 [278, 277, 277]\n",
      "295 [279, 278, 278]\n",
      "296 [280, 279, 279]\n",
      "297 [281, 280, 280]\n",
      "298 [282, 281, 281]\n",
      "299 [283, 282, 282]\n",
      "300 [283, 282, 282]\n",
      "301 [283, 283, 283]\n",
      "302 [284, 284, 284]\n",
      "303 [285, 285, 285]\n",
      "304 [286, 286, 286]\n",
      "305 [287, 287, 287]\n",
      "306 [288, 288, 288]\n",
      "307 [289, 289, 289]\n",
      "308 [290, 290, 290]\n",
      "309 [291, 291, 291]\n",
      "310 [292, 292, 292]\n",
      "311 [293, 293, 293]\n",
      "312 [294, 294, 294]\n",
      "313 [295, 295, 295]\n",
      "314 [296, 296, 296]\n",
      "315 [297, 297, 297]\n",
      "316 [298, 298, 298]\n",
      "317 [299, 299, 299]\n",
      "318 [300, 300, 300]\n",
      "319 [300, 300, 300]\n",
      "320 [301, 301, 301]\n",
      "321 [302, 302, 302]\n",
      "322 [303, 303, 303]\n",
      "323 [304, 304, 304]\n",
      "324 [305, 305, 305]\n",
      "325 [306, 306, 306]\n",
      "326 [307, 307, 307]\n",
      "327 [308, 308, 308]\n",
      "328 [309, 309, 309]\n",
      "329 [310, 310, 310]\n",
      "330 [311, 311, 311]\n",
      "331 [311, 312, 312]\n",
      "332 [312, 313, 313]\n",
      "333 [313, 314, 314]\n",
      "334 [314, 315, 315]\n",
      "335 [315, 316, 316]\n",
      "336 [316, 317, 317]\n",
      "337 [317, 318, 318]\n",
      "338 [318, 319, 319]\n",
      "339 [319, 320, 320]\n",
      "340 [320, 321, 321]\n",
      "341 [321, 322, 322]\n",
      "342 [322, 323, 323]\n",
      "343 [323, 324, 324]\n",
      "344 [324, 325, 325]\n",
      "345 [325, 326, 326]\n",
      "346 [326, 327, 327]\n",
      "347 [327, 328, 328]\n",
      "348 [328, 329, 329]\n",
      "349 [329, 330, 330]\n",
      "350 [330, 331, 331]\n",
      "351 [331, 332, 332]\n",
      "352 [332, 333, 333]\n",
      "353 [333, 334, 334]\n",
      "354 [334, 335, 335]\n",
      "355 [335, 336, 336]\n",
      "356 [336, 337, 337]\n",
      "357 [337, 338, 338]\n",
      "358 [338, 339, 339]\n",
      "359 [338, 339, 339]\n",
      "360 [339, 340, 340]\n",
      "361 [340, 341, 341]\n",
      "362 [341, 342, 342]\n",
      "363 [342, 343, 343]\n",
      "364 [343, 344, 344]\n",
      "365 [344, 345, 345]\n",
      "366 [345, 346, 346]\n",
      "367 [346, 347, 347]\n",
      "368 [347, 348, 348]\n",
      "369 [348, 349, 349]\n",
      "370 [349, 350, 350]\n",
      "371 [350, 351, 351]\n",
      "372 [351, 352, 352]\n",
      "373 [352, 353, 353]\n",
      "374 [353, 354, 354]\n",
      "375 [354, 355, 355]\n",
      "376 [355, 356, 356]\n",
      "377 [356, 357, 357]\n",
      "378 [357, 358, 358]\n",
      "379 [358, 359, 359]\n",
      "380 [359, 360, 360]\n",
      "381 [360, 361, 361]\n",
      "382 [361, 362, 362]\n",
      "383 [362, 363, 363]\n",
      "384 [363, 364, 364]\n",
      "385 [364, 365, 365]\n",
      "386 [365, 366, 366]\n",
      "387 [366, 367, 367]\n",
      "388 [367, 368, 368]\n",
      "389 [368, 369, 369]\n",
      "390 [369, 370, 370]\n",
      "391 [370, 371, 371]\n",
      "392 [371, 372, 372]\n",
      "393 [372, 373, 373]\n",
      "394 [373, 374, 374]\n",
      "395 [374, 375, 375]\n",
      "396 [375, 376, 376]\n",
      "397 [376, 377, 377]\n",
      "398 [376, 378, 378]\n",
      "399 [377, 379, 379]\n",
      "400 [378, 380, 380]\n",
      "401 [379, 381, 381]\n",
      "402 [380, 382, 382]\n",
      "403 [381, 383, 383]\n",
      "404 [382, 384, 384]\n",
      "405 [383, 385, 385]\n",
      "406 [384, 386, 386]\n",
      "407 [385, 387, 387]\n",
      "408 [386, 387, 387]\n",
      "409 [387, 388, 388]\n",
      "410 [388, 389, 389]\n",
      "411 [389, 390, 390]\n",
      "412 [390, 391, 391]\n",
      "413 [391, 392, 392]\n",
      "414 [392, 393, 393]\n",
      "415 [392, 393, 393]\n",
      "416 [393, 394, 393]\n",
      "417 [394, 395, 394]\n",
      "418 [395, 396, 395]\n",
      "419 [396, 397, 396]\n",
      "420 [397, 398, 397]\n",
      "421 [398, 399, 398]\n",
      "422 [399, 400, 399]\n",
      "423 [400, 401, 400]\n",
      "424 [401, 402, 401]\n",
      "425 [402, 403, 402]\n",
      "426 [403, 404, 403]\n",
      "427 [404, 405, 404]\n",
      "428 [404, 405, 404]\n",
      "429 [405, 406, 405]\n",
      "430 [406, 407, 406]\n",
      "431 [406, 408, 407]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "432 [407, 409, 408]\n",
      "433 [408, 410, 409]\n",
      "434 [409, 411, 410]\n",
      "435 [410, 412, 411]\n",
      "436 [410, 412, 411]\n",
      "437 [411, 413, 412]\n",
      "438 [412, 414, 413]\n",
      "439 [413, 415, 414]\n",
      "440 [414, 416, 415]\n",
      "441 [414, 416, 415]\n",
      "442 [414, 417, 416]\n",
      "443 [415, 418, 417]\n",
      "444 [416, 419, 418]\n",
      "445 [416, 419, 418]\n",
      "446 [417, 420, 419]\n",
      "447 [417, 421, 420]\n",
      "448 [418, 422, 421]\n",
      "449 [419, 423, 422]\n",
      "450 [420, 424, 423]\n",
      "451 [421, 425, 424]\n",
      "452 [422, 426, 425]\n",
      "453 [423, 427, 426]\n",
      "454 [424, 428, 427]\n",
      "455 [424, 428, 427]\n",
      "456 [425, 429, 428]\n",
      "457 [426, 430, 429]\n",
      "458 [427, 431, 430]\n",
      "459 [427, 432, 431]\n",
      "460 [428, 433, 432]\n",
      "461 [429, 433, 432]\n",
      "462 [430, 434, 433]\n",
      "463 [431, 435, 434]\n",
      "464 [432, 436, 435]\n",
      "465 [433, 436, 435]\n",
      "466 [434, 437, 436]\n",
      "467 [434, 437, 436]\n",
      "468 [434, 437, 436]\n",
      "469 [435, 438, 437]\n",
      "470 [436, 439, 438]\n",
      "471 [437, 439, 438]\n",
      "472 [437, 439, 438]\n",
      "473 [437, 439, 438]\n",
      "474 [438, 440, 439]\n",
      "475 [439, 441, 440]\n",
      "476 [440, 442, 441]\n",
      "477 [441, 443, 442]\n",
      "478 [441, 444, 443]\n",
      "479 [442, 445, 444]\n",
      "480 [443, 446, 445]\n",
      "481 [444, 447, 446]\n",
      "482 [444, 447, 447]\n",
      "483 [445, 448, 448]\n",
      "484 [446, 448, 449]\n",
      "485 [447, 449, 450]\n",
      "486 [448, 450, 451]\n",
      "487 [449, 451, 452]\n",
      "488 [450, 452, 453]\n",
      "489 [451, 453, 454]\n",
      "490 [452, 454, 455]\n",
      "491 [453, 455, 456]\n",
      "492 [454, 456, 457]\n",
      "493 [455, 457, 458]\n",
      "494 [456, 458, 459]\n",
      "495 [457, 459, 460]\n",
      "496 [458, 460, 461]\n",
      "497 [458, 460, 461]\n",
      "498 [459, 461, 462]\n",
      "499 [460, 462, 463]\n",
      "500 [461, 463, 464]\n",
      "501 [462, 464, 465]\n",
      "502 [463, 465, 466]\n",
      "503 [464, 466, 467]\n",
      "504 [465, 467, 468]\n",
      "505 [466, 468, 469]\n",
      "506 [467, 469, 470]\n",
      "507 [467, 469, 470]\n",
      "508 [467, 470, 471]\n",
      "509 [468, 471, 472]\n",
      "510 [469, 472, 473]\n",
      "511 [470, 473, 474]\n",
      "512 [471, 474, 475]\n",
      "513 [472, 475, 476]\n",
      "514 [473, 476, 477]\n",
      "515 [474, 477, 478]\n",
      "516 [475, 478, 479]\n",
      "517 [476, 479, 480]\n",
      "518 [476, 479, 480]\n",
      "519 [477, 480, 481]\n",
      "520 [478, 481, 482]\n",
      "521 [479, 482, 483]\n",
      "522 [480, 483, 484]\n",
      "523 [481, 484, 485]\n",
      "524 [482, 485, 486]\n",
      "525 [483, 486, 487]\n",
      "526 [484, 487, 488]\n",
      "527 [485, 488, 489]\n",
      "528 [486, 489, 490]\n",
      "529 [487, 490, 491]\n",
      "530 [488, 491, 492]\n",
      "531 [489, 492, 493]\n",
      "532 [490, 493, 494]\n",
      "533 [491, 494, 495]\n",
      "534 [492, 495, 496]\n",
      "535 [493, 496, 497]\n",
      "536 [494, 497, 498]\n",
      "537 [495, 498, 499]\n",
      "538 [495, 498, 499]\n",
      "539 [496, 499, 500]\n",
      "540 [497, 500, 501]\n",
      "541 [498, 501, 502]\n",
      "542 [499, 502, 503]\n",
      "543 [500, 503, 504]\n",
      "544 [501, 504, 504]\n",
      "545 [502, 505, 505]\n",
      "546 [503, 505, 505]\n",
      "547 [504, 506, 506]\n",
      "548 [505, 507, 507]\n",
      "549 [506, 508, 508]\n",
      "550 [507, 509, 509]\n",
      "551 [508, 510, 510]\n",
      "552 [508, 510, 510]\n",
      "553 [509, 511, 511]\n",
      "554 [510, 512, 512]\n",
      "555 [511, 513, 513]\n",
      "556 [512, 514, 514]\n",
      "557 [513, 515, 515]\n",
      "558 [514, 516, 516]\n",
      "559 [515, 517, 517]\n",
      "560 [516, 518, 518]\n",
      "561 [517, 519, 519]\n",
      "562 [517, 520, 520]\n",
      "563 [518, 521, 521]\n",
      "564 [519, 522, 522]\n",
      "565 [520, 523, 523]\n",
      "566 [521, 524, 524]\n",
      "567 [522, 525, 525]\n",
      "568 [522, 525, 525]\n",
      "569 [522, 525, 525]\n",
      "570 [523, 526, 526]\n",
      "571 [523, 526, 526]\n",
      "572 [524, 527, 527]\n",
      "573 [525, 528, 528]\n",
      "574 [526, 529, 529]\n",
      "575 [526, 530, 530]\n",
      "576 [527, 531, 531]\n",
      "577 [528, 532, 532]\n",
      "578 [529, 533, 533]\n",
      "579 [530, 534, 534]\n",
      "580 [531, 535, 535]\n",
      "581 [532, 536, 536]\n",
      "582 [532, 536, 537]\n",
      "583 [533, 537, 538]\n",
      "584 [534, 537, 539]\n",
      "585 [535, 538, 540]\n",
      "586 [536, 539, 540]\n",
      "587 [536, 539, 540]\n",
      "588 [536, 539, 540]\n",
      "589 [537, 540, 541]\n",
      "590 [538, 541, 542]\n",
      "591 [538, 541, 542]\n",
      "592 [539, 542, 543]\n",
      "593 [540, 543, 544]\n",
      "594 [541, 544, 545]\n",
      "595 [542, 545, 546]\n",
      "596 [543, 546, 547]\n",
      "597 [544, 547, 548]\n",
      "598 [545, 548, 549]\n",
      "599 [546, 548, 549]\n",
      "Accuracy is:  91.0\n",
      "Accuracy is:  91.33333333333333\n",
      "Accuracy is:  91.5\n"
     ]
    }
   ],
   "source": [
    "def CosineValidation_Test(X_Validation_ED, Y_Validation, X_train_ED, Y_train, K):\n",
    "    count = [0,0,0]\n",
    "    for i in range(len(X_Validation_ED)):\n",
    "        result = CosineSimilarity(X_Validation_ED[i], X_train_ED, Y_train, K)\n",
    "        for k in range(len(K)):\n",
    "            if Y_Validation[i] == result[k]:\n",
    "                count[k] += 1\n",
    "        print(i, count)\n",
    "    \n",
    "    for k in range(len(K)):\n",
    "        print(\"Accuracy is: \", (count[k]/len(Y_Validation) * 100))\n",
    "#     return (count/len(Y_Validation) * 100)\n",
    "\n",
    "CosineValidation_Test(deepcopy(X_Validation_ED), deepcopy(Y_Validation), deepcopy(X_train_ED), deepcopy(Y_train), K)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 252,
   "metadata": {},
   "outputs": [],
   "source": [
    "def denominatorOfNB(Dt,alpha):\n",
    "    summation = 0\n",
    "    \n",
    "    for i in range(len(TopicName)):\n",
    "        summation += Prob_DT_CM(Dt,i, alpha)\n",
    "    \n",
    "    return summation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 244,
   "metadata": {},
   "outputs": [],
   "source": [
    "def Prob_Wj_Cm(word, m, alpha):\n",
    "    \n",
    "    frequencyOf_W_in_M = 0\n",
    "    TotalWords_in_M = len(CM_list[m])\n",
    "    \n",
    "    for i in range(len(CM_list[m])):\n",
    "        frequencyOf_W_in_M += CM_list[m][i].count(word)\n",
    "        \n",
    "    value = (frequencyOf_W_in_M + alpha)/ (TotalWords_in_M + alpha * len(FeatureSpace))\n",
    "    \n",
    "    if value == 0:\n",
    "        print(m, \"e jhamela ache \", value, \"->\", word)\n",
    "\n",
    "    return value"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 245,
   "metadata": {},
   "outputs": [],
   "source": [
    "def Prob_DT_CM(Dt, m, alpha):\n",
    "    P_Dt_Cm = 1\n",
    "    \n",
    "    for i in range(len(Dt)):\n",
    "        if(Dt[i] != 0):\n",
    "            P_Dt_Cm *= Prob_Wj_Cm(FeatureSpace[i],m, alpha)\n",
    "#             print(P_Dt_Cm)\n",
    "    \n",
    "#     print(\"probab of DT being in \", m, \" is \", P_Dt_Cm)\n",
    "    return P_Dt_Cm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 249,
   "metadata": {},
   "outputs": [],
   "source": [
    "def NaiveBayes(Dt, m, denom, alpha):\n",
    "    value = (Prob_DT_CM(Dt,m,alpha) * (1/len(CM_list)))/ (denom + alpha*len(FeatureSpace))\n",
    "    return value"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 259,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[2, 1.5, 0.2]\n"
     ]
    }
   ],
   "source": [
    "# Probability = []\n",
    "# denom = denominatorOfNB(X_Validation_ED[6])\n",
    "# # for i in range(len(CM_list)):\n",
    "# #     Probability.append(NaiveBayes(X_Validation_ED[6],i, denom))\n",
    "\n",
    "# # # print(Probability)    \n",
    "# # print(TopicName[Probability.index(max(Probability))][0])\n",
    "# print(denom)\n",
    "\n",
    "# print(len(X_Validation_HD[6]))\n",
    "# # len(CM_list)\n",
    "\n",
    "x = [2, 1.5, 0.2] \n",
    "print(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 255,
   "metadata": {},
   "outputs": [],
   "source": [
    "def NB_precision(X_Validation_HD, Y_Validation, alpha):\n",
    "    count = 0\n",
    "    for itr in range(len(X_Validation_HD)):\n",
    "        Probability = []\n",
    "        denom = denominatorOfNB(X_Validation_HD[itr], alpha)\n",
    "#         if denom == 0:\n",
    "#             continue\n",
    "        for i in range(len(CM_list)):\n",
    "            Probability.append(NaiveBayes(X_Validation_HD[itr],i, denom, alpha))\n",
    "        \n",
    "        prediction = TopicName[Probability.index(max(Probability))][0]\n",
    "        if prediction == Y_Validation[itr]:\n",
    "            count += 1\n",
    "#             print(count)\n",
    "    \n",
    "    print(\"Accuracy is: \", (count/len(Y_Validation) * 100)) \n",
    "\n",
    "# NB_precision(X_Validation_HD, Y_Validation, 0.01)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 261,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy is:  91.66666666666666\n",
      "2\n",
      "--------------------------\n",
      "Accuracy is:  91.83333333333333\n",
      "1.5\n",
      "--------------------------\n",
      "Accuracy is:  95.66666666666667\n",
      "0.2\n",
      "--------------------------\n"
     ]
    }
   ],
   "source": [
    "for alpha in x:\n",
    "    NB_precision(X_Validation_HD, Y_Validation, alpha)\n",
    "    print(alpha)\n",
    "    print(\"--------------------------\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 137,
   "metadata": {},
   "outputs": [],
   "source": [
    "TopicName = []\n",
    "x=[d.keys() for d in Training_set]\n",
    "for keys in x:\n",
    "    if list(keys) not in TopicName:\n",
    "        TopicName.append(list(keys))\n",
    "\n",
    "CM_list = []\n",
    "\n",
    "for j in range(len(TopicName)):\n",
    "    CM_list.append([])\n",
    "    for i in range(len(Training_set)):\n",
    "        if list(Training_set[i].keys()) == TopicName[j]:\n",
    "            y = list(Training_set[i].values())[0]\n",
    "            CM_list[j].append(y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
