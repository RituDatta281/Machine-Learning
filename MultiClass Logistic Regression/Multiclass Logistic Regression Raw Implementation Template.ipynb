{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Import required python module(s)\n",
    "import numpy as np \n",
    "import math"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[5.1 3.5 1.4 0.2]\n",
      " [4.9 3.  1.4 0.2]\n",
      " [4.7 3.2 1.3 0.2]\n",
      " [4.6 3.1 1.5 0.2]\n",
      " [5.  3.6 1.4 0.2]\n",
      " [5.4 3.9 1.7 0.4]\n",
      " [4.6 3.4 1.4 0.3]\n",
      " [5.  3.4 1.5 0.2]\n",
      " [4.4 2.9 1.4 0.2]\n",
      " [4.9 3.1 1.5 0.1]\n",
      " [5.4 3.7 1.5 0.2]\n",
      " [4.8 3.4 1.6 0.2]\n",
      " [4.8 3.  1.4 0.1]\n",
      " [4.3 3.  1.1 0.1]\n",
      " [5.8 4.  1.2 0.2]\n",
      " [5.7 4.4 1.5 0.4]\n",
      " [5.4 3.9 1.3 0.4]\n",
      " [5.1 3.5 1.4 0.3]\n",
      " [5.7 3.8 1.7 0.3]\n",
      " [5.1 3.8 1.5 0.3]\n",
      " [5.4 3.4 1.7 0.2]\n",
      " [5.1 3.7 1.5 0.4]\n",
      " [4.6 3.6 1.  0.2]\n",
      " [5.1 3.3 1.7 0.5]\n",
      " [4.8 3.4 1.9 0.2]\n",
      " [5.  3.  1.6 0.2]\n",
      " [5.  3.4 1.6 0.4]\n",
      " [5.2 3.5 1.5 0.2]\n",
      " [5.2 3.4 1.4 0.2]\n",
      " [4.7 3.2 1.6 0.2]\n",
      " [4.8 3.1 1.6 0.2]\n",
      " [5.4 3.4 1.5 0.4]\n",
      " [5.2 4.1 1.5 0.1]\n",
      " [5.5 4.2 1.4 0.2]\n",
      " [4.9 3.1 1.5 0.1]\n",
      " [5.  3.2 1.2 0.2]\n",
      " [5.5 3.5 1.3 0.2]\n",
      " [4.9 3.1 1.5 0.1]\n",
      " [4.4 3.  1.3 0.2]\n",
      " [5.1 3.4 1.5 0.2]\n",
      " [5.  2.  3.5 1. ]\n",
      " [5.9 3.  4.2 1.5]\n",
      " [6.  2.2 4.  1. ]\n",
      " [6.1 2.9 4.7 1.4]\n",
      " [5.6 2.9 3.6 1.3]\n",
      " [6.7 3.1 4.4 1.4]\n",
      " [5.6 3.  4.5 1.5]\n",
      " [5.8 2.7 4.1 1. ]\n",
      " [6.2 2.2 4.5 1.5]\n",
      " [5.6 2.5 3.9 1.1]\n",
      " [5.9 3.2 4.8 1.8]\n",
      " [6.1 2.8 4.  1.3]\n",
      " [6.3 2.5 4.9 1.5]\n",
      " [6.1 2.8 4.7 1.2]\n",
      " [6.4 2.9 4.3 1.3]\n",
      " [6.6 3.  4.4 1.4]\n",
      " [6.8 2.8 4.8 1.4]\n",
      " [6.7 3.  5.  1.7]\n",
      " [6.  2.9 4.5 1.5]\n",
      " [5.7 2.6 3.5 1. ]\n",
      " [5.5 2.4 3.8 1.1]\n",
      " [5.5 2.4 3.7 1. ]\n",
      " [5.8 2.7 3.9 1.2]\n",
      " [6.  2.7 5.1 1.6]\n",
      " [5.4 3.  4.5 1.5]\n",
      " [6.  3.4 4.5 1.6]\n",
      " [6.7 3.1 4.7 1.5]\n",
      " [6.3 2.3 4.4 1.3]\n",
      " [5.6 3.  4.1 1.3]\n",
      " [5.5 2.5 4.  1.3]\n",
      " [5.5 2.6 4.4 1.2]\n",
      " [6.1 3.  4.6 1.4]\n",
      " [5.8 2.6 4.  1.2]\n",
      " [5.  2.3 3.3 1. ]\n",
      " [5.6 2.7 4.2 1.3]\n",
      " [5.7 3.  4.2 1.2]\n",
      " [5.7 2.9 4.2 1.3]\n",
      " [6.2 2.9 4.3 1.3]\n",
      " [5.1 2.5 3.  1.1]\n",
      " [5.7 2.8 4.1 1.3]\n",
      " [6.3 3.3 6.  2.5]\n",
      " [5.8 2.7 5.1 1.9]\n",
      " [7.1 3.  5.9 2.1]\n",
      " [6.3 2.9 5.6 1.8]\n",
      " [6.5 3.  5.8 2.2]\n",
      " [7.6 3.  6.6 2.1]\n",
      " [4.9 2.5 4.5 1.7]\n",
      " [7.3 2.9 6.3 1.8]\n",
      " [6.7 2.5 5.8 1.8]\n",
      " [7.2 3.6 6.1 2.5]\n",
      " [6.5 3.2 5.1 2. ]\n",
      " [6.4 2.7 5.3 1.9]\n",
      " [6.8 3.  5.5 2.1]\n",
      " [5.7 2.5 5.  2. ]\n",
      " [5.8 2.8 5.1 2.4]\n",
      " [6.4 3.2 5.3 2.3]\n",
      " [6.5 3.  5.5 1.8]\n",
      " [7.7 3.8 6.7 2.2]\n",
      " [7.7 2.6 6.9 2.3]\n",
      " [6.  2.2 5.  1.5]\n",
      " [6.9 3.2 5.7 2.3]\n",
      " [5.6 2.8 4.9 2. ]\n",
      " [7.7 2.8 6.7 2. ]\n",
      " [6.3 2.7 4.9 1.8]\n",
      " [6.7 3.3 5.7 2.1]\n",
      " [7.2 3.2 6.  1.8]\n",
      " [6.2 2.8 4.8 1.8]\n",
      " [6.1 3.  4.9 1.8]\n",
      " [6.4 2.8 5.6 2.1]\n",
      " [7.2 3.  5.8 1.6]\n",
      " [7.4 2.8 6.1 1.9]\n",
      " [7.9 3.8 6.4 2. ]\n",
      " [6.4 2.8 5.6 2.2]\n",
      " [6.3 2.8 5.1 1.5]\n",
      " [6.1 2.6 5.6 1.4]\n",
      " [7.7 3.  6.1 2.3]\n",
      " [6.3 3.4 5.6 2.4]\n",
      " [6.4 3.1 5.5 1.8]\n",
      " [6.  3.  4.8 1.8]\n",
      " [6.9 3.1 5.4 2.1]]\n"
     ]
    }
   ],
   "source": [
    "#load data from file\n",
    "data = np.genfromtxt('iris_multiclass.csv', delimiter=',',skip_header=True)\n",
    "\n",
    "#Distribute data into train and test sets\n",
    "X_train = data[:120,[0,1,2,3]]\n",
    "Y_train = data[:120,5]\n",
    "\n",
    "X_test = data[-30:,[0,1,2,3]]\n",
    "Y_test = data[-30:,5]\n",
    "print(X_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Define the required Sigmoid function\n",
    "def sigmoid(z):\n",
    "    return 1/(1+np.exp(-z))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "10.378601487723103\n",
      "[[ 0.22847044]\n",
      " [ 0.44091318]\n",
      " [ 1.23995218]\n",
      " [-1.81987437]\n",
      " [-0.82854044]]\n",
      "-70.33546027675919\n",
      "[[ 0.09826248]\n",
      " [ 0.02460187]\n",
      " [-0.63717618]\n",
      " [ 0.31374286]\n",
      " [-0.13328148]]\n",
      "-27.26219766778988\n",
      "[[-0.37396398]\n",
      " [-0.78009153]\n",
      " [-0.84510509]\n",
      " [ 1.33644729]\n",
      " [ 0.8901122 ]]\n"
     ]
    }
   ],
   "source": [
    "#Define the Raw implementation function to set the parameters (theta)\n",
    "\n",
    "def fit_implementation(X_train, Y_train, learning_rate=0.0001, max_iteration=1000, debug=False):\n",
    "    #Adding a column of 1's so that the first element of each input is always 1\n",
    "    #It would be multiplied with theta_0 later\n",
    "    X_train= np.insert(X_train, 0, values=1, axis=1)\n",
    "    no_attributes = X_train.shape[1]\n",
    "    \n",
    "    #Initialize model parameters theta\n",
    "    theta = np.zeros((no_attributes,1))\n",
    "    \n",
    "    #Run number of iterations\n",
    "    for icount in range(max_iteration):\n",
    "        #delta is the quantity that will be added with theta during updating theta\n",
    "        delta = np.zeros((no_attributes,1))\n",
    "        totalLogLikelihood = 0\n",
    "        #Check each data point\n",
    "        for instance, actualOutput in zip(X_train,Y_train):\n",
    "            instance=instance.reshape(no_attributes,1)\n",
    "            dotResult = np.dot(theta.T, instance)            \n",
    "            predictedValue=sigmoid(dotResult).squeeze()\n",
    "            #Calculate the derivative value for this data point\n",
    "            derivativeValue = instance*(actualOutput-predictedValue)\n",
    "            #Calculate the amount to be added with theta\n",
    "            delta += learning_rate*derivativeValue\n",
    "#             if predictedValue==1:\n",
    "#                 print(\"instance\",instance)\n",
    "#                 print(\"dot result\",dotResult)\n",
    "            logLikelihood = actualOutput*np.log(predictedValue)+(1-actualOutput)*np.log(1-predictedValue)\n",
    "            totalLogLikelihood += logLikelihood\n",
    "        theta = theta + delta\n",
    "        #After each 100 iteration, print the status\n",
    "        if icount%100==0 and debug==True:\n",
    "            print(icount)\n",
    "            print(totalLogLikelihood)\n",
    "            print(theta)\n",
    "            \n",
    "    print(totalLogLikelihood)\n",
    "    print(theta)\n",
    "    \n",
    "    return theta\n",
    "\n",
    "\n",
    "def multiClassFitImplementation(X_train, Y_train):\n",
    "    #Determine the list unique classes (unique target variable values) \n",
    "    #Changes required here\n",
    "    Unique_Classes = np.unique(Y_train)\n",
    "    #For each uniqueclass, determine the best classifier/parameter/theta which best separates the class with others\n",
    "    #You can temporarily modify Y_train data to achieve the target and can call the fit_implementation function\n",
    "    parameters = dict()\n",
    "    #Changes required here   \n",
    "    for classes in (Unique_Classes):\n",
    "        temp_Y_train = []\n",
    "        for itr in range(len(Y_train)):\n",
    "            if Y_train[itr] != classes:\n",
    "                temp_Y_train.append(0.0)\n",
    "            else:\n",
    "                temp_Y_train.append(1.1)\n",
    "#         print(temp_Y_train)\n",
    "        parameters[classes] = fit_implementation(X_train, temp_Y_train)\n",
    "    \n",
    "\n",
    "    return parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "metadata": {},
   "outputs": [],
   "source": [
    "#One of the following parameters of the function is now thetas which is a dictionary containing (targetClass,theta) \n",
    "#as (key,value) pairs for all target classes\n",
    "def prediction(X_test, Y_test, thetas):\n",
    "    #Adding a column of 1's so that the first element of each input is always 1\n",
    "    #It would be multiplied with theta_0 later\n",
    "    X_test= np.insert(X_test, 0, values=1, axis=1)\n",
    "    no_attributes = X_test.shape[1]\n",
    "    \n",
    "    correctCount = 0\n",
    "    totalCount = 0\n",
    "    \n",
    "    maxPredictedValue = -10000\n",
    "    predictedClass = 1.0\n",
    "    \n",
    "    #Check each data point\n",
    "    for instance, actualOutput in zip(X_test,Y_test):\n",
    "            instance=instance.reshape(no_attributes,1)\n",
    "            #Determine the maximum predicted value and predictedClass\n",
    "            #Changes required here\n",
    "            predictedValue = []\n",
    "            for classes in parameters:\n",
    "                dotResult = np.dot(parameters[classes].T, instance)\n",
    "                predictedValue.append(sigmoid(dotResult).squeeze())\n",
    "            predictedOutput = predictedValue.index(max(predictedValue))+1\n",
    "            print(predictedOutput,\" \", actualOutput)\n",
    "            if predictedOutput == actualOutput:\n",
    "                correctCount += 1\n",
    "            totalCount += 1\n",
    "    print(\"Total Correct Count: \",correctCount,\" Total Wrong Count: \",totalCount-correctCount,\" Accuracy: \",(correctCount*100)/(totalCount))\n",
    "    \n",
    "#             print(maxPredictedValue, predictedClass, actualOutput)\n",
    "#             if predictedClass == actualOutput:\n",
    "#                 correctCount += 1\n",
    "#             totalCount += 1\n",
    "#     print(\"Total Correct Count: \",correctCount,\" Total Wrong Count: \",totalCount-correctCount,\" Accuracy: \",(correctCount*100)/(totalCount))\n",
    " "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Expected Output: \n",
    "Total Correct Count:  30  Total Wrong Count:  0  Accuracy:  100.0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 113,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1   1.0\n",
      "1   1.0\n",
      "1   1.0\n",
      "1   1.0\n",
      "1   1.0\n",
      "2   2.0\n",
      "2   2.0\n",
      "2   2.0\n",
      "3   2.0\n",
      "2   2.0\n",
      "3   3.0\n",
      "3   3.0\n",
      "3   3.0\n",
      "3   3.0\n",
      "3   3.0\n",
      "1   1.0\n",
      "1   1.0\n",
      "1   1.0\n",
      "1   1.0\n",
      "1   1.0\n",
      "3   2.0\n",
      "3   2.0\n",
      "2   2.0\n",
      "2   2.0\n",
      "3   2.0\n",
      "3   3.0\n",
      "3   3.0\n",
      "3   3.0\n",
      "3   3.0\n",
      "3   3.0\n"
     ]
    }
   ],
   "source": [
    "#parameters = multiClassFitImplementation(X_train, Y_train)\n",
    "prediction(X_test, Y_test, parameters)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
